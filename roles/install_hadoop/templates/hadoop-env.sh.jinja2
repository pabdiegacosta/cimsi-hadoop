# Hadoop Environment Variables

# Set Java Home
export JAVA_HOME={{ hdfs_java_home }}
export HADOOP_HOME={{ hdfs_hadoop_home | default('/usr/hadoop') }}
# export SPARK_HOME
# export PYSPARK_PYTHON
export HADOOP_HEAPSIZE={{ hdfs_hadoop_heapsize | default(1024) }}
export HADOOP_LOG_DIR={{ hdfs_hadoop_log_dir | default('/var/log/hadoop') }}
export HADOOP_PID_DIR={{ hdfs_hadoop_pid_dir | default('/var/run/hadoop') }}


# The user running Hadoop processes
export HDFS_NAMENODE_USER={{ hdfs_namenode_user | default('master') }}
export HDFS_DATANODE_USER={{ hdfs_datanode_user | default('worker') }}

export HADOOP_NAMENODE_OPTS="{{ hdfs_namenode_opts | default('-Xmx2048m') }} $HADOOP_NAMENODE_OPTS"
export YARN_RESOURCEMANAGER_OPTS="{{ yarn_resourcemanager_opts | default('-Xmx1024m') }} $YARN_RESOURCEMANAGER_OPTS"

export HADOOP_DATANODE_OPTS="{{ hdfs_datanode_opts | default('-Xmx1024m') }} $HADOOP_DATANODE_OPTS"
export YARN_NODEMANAGER_OPTS="{{ yarn_nodemanager_opts | default('-Xmx512m') }} $YARN_NODEMANAGER_OPTS"

# Hadoop options
# export HADOOP_OPTS="-Djava.net.preferIPv4Stack=true"

# Add Hadoop binary directories to the path
export PATH=$PATH:{{ hdfs_hadoop_home }}/bin:{{ hdfs_hadoop_home }}/sbin

